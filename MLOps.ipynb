{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Задание 2 \"Мониторинг в сельском хозяйстве\"\n",
        "\n",
        "---\n",
        "\n",
        "**Курс:** Проектирование систем машинного обучения  \n",
        "**Студент:** Безмылов А.П.    \n",
        "**Группа:** М80-210СВ-24  \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "# 1. Введение и постановка задачи\n",
        "---\n",
        "Задача: Спроектируйте систему с использованием изображений с дронов для выявления болезней сельскохозяйственных культур. Сосредоточьтесь на обработке больших объемов изображений и обновлении моделей.\n",
        "\n",
        "В сельском хозяйстве заболевания растений являются одной из ключевых причин снижения урожайности и роста операционных затрат. Несвоевременное выявление фитопатологий приводит к распространению болезней на большие площади и необходимости массового применения средств защиты растений.\n",
        "\n",
        "В рамках данного проекта разрабатывается **промышленная ML-система мониторинга здоровья сельскохозяйственных культур**, основанная на анализе изображений, получаемых с дронов, оснащённых мультиспектральными камерами. Система ориентирована на автоматическую обработку больших потоков изображений, выявление и локализацию зон поражения растений и предоставление аналитики агрономам вблизи реального времени.\n",
        "\n",
        "Проектируемая система должна быть масштабируемой, отказоустойчивой и способной автоматически адаптироваться к изменениям данных (сезонность, новые заболевания, изменения условий съёмки).\n",
        "\n",
        "\n",
        "\n",
        "## Бизнес-цели\n",
        "\n",
        "1. **Снижение потерь урожая**  \n",
        "   Раннее выявление заболеваний и стрессовых зон растений с целью снижения потерь урожайности на **30–40%**.\n",
        "\n",
        "2. **Оптимизация затрат на агроскаутинг**  \n",
        "   Сокращение ручных осмотров полей и затрат на персонал до **60%** за счёт автоматизированного анализа данных с дронов.\n",
        "\n",
        "3. **Повышение эффективности обработки полей**  \n",
        "   Обеспечение точечного внесения удобрений и средств защиты растений, что позволяет снизить перерасход химикатов до **25%**.\n",
        "\n",
        "\n",
        "## Требования к системе\n",
        "\n",
        "### Производительность и нагрузка\n",
        "\n",
        "- **Задержка (latency):**  \n",
        "  Время обработки одного изображения — не более **490 мс**.\n",
        "\n",
        "- **Пропускная способность (throughput):**  \n",
        "  Поддержка пиковых нагрузок до **2 334 запросов в секунду (RPS)**, возникающих при массовых облётах полей.\n",
        "\n",
        "- **Пользовательская нагрузка:**  \n",
        "  До **4 673 977 активных пользователей в день (DAU)**, включая агрономов, фермеров и автоматические сервисы анализа.\n",
        "\n",
        "### Надёжность и масштабируемость\n",
        "\n",
        "- Горизонтальное масштабирование inference-сервисов.  \n",
        "- Отсутствие single point of failure.  \n",
        "- Поддержка multi-AZ / multi-ЦОД размещения ключевых компонентов.\n",
        "---\n",
        "# Часть 1. Формулировка ML-задачи и выбор модели\n",
        "---\n",
        "# 1.1 Определение ML-задачи\n",
        "\n",
        "### Формулировка задачи\n",
        "\n",
        "Задача мониторинга состояния сельскохозяйственных культур формулируется как задача **детекции и сегментации заболеваний растений на изображениях с дронов**.\n",
        "\n",
        "Для каждого входного изображения необходимо:\n",
        "\n",
        "- определить наличие заболеваний;\n",
        "- классифицировать тип заболевания;\n",
        "- локализовать поражённые участки на изображении.\n",
        "\n",
        "### Обоснование постановки задачи\n",
        "\n",
        "- Одно изображение может содержать несколько зон поражения с разной степенью выраженности.  \n",
        "- Для принятия агрономических решений важно понимать **пространственное распределение** заболеваний по полю.  \n",
        "- Использование только классификации без локализации не позволяет оценить площадь поражения и спланировать обработку.\n",
        "\n",
        "Таким образом, задача относится к классу **object detection / instance segmentation**.\n",
        "\n",
        "### Входные данные\n",
        "\n",
        "- Изображения с дронов:\n",
        "  - RGB (опционно);\n",
        "  - мультиспектральные каналы (NIR, Red Edge, Red).\n",
        "- Метаданные съёмки:\n",
        "  - геопозиция;\n",
        "  - время съёмки;\n",
        "  - параметры полёта.\n",
        "\n",
        "### Выходные данные\n",
        "\n",
        "- Bounding boxes или маски поражённых участков.\n",
        "- Класс заболевания.\n",
        "- Оценка степени поражения (confidence score).\n",
        "\n",
        "### Целевая переменная\n",
        "\n",
        "- Координаты bounding boxes (или сегментационные маски).  \n",
        "- Класс заболевания для каждой области.\n",
        "\n",
        "# 1.2 Выбор модели\n",
        "\n",
        "Для решения поставленной задачи были рассмотрены несколько архитектур компьютерного зрения.\n",
        "\n",
        "### Модель 1: YOLOv11\n",
        "\n",
        "**Преимущества:**\n",
        "\n",
        "- высокая скорость инференса, критичная при нагрузке до 2 334 RPS;\n",
        "- одновременная детекция и классификация;\n",
        "- хорошая масштабируемость при запуске в Kubernetes;\n",
        "- поддержка экспорта в ONNX и оптимизации под GPU;\n",
        "- эффективная работа с мультиспектральными каналами.\n",
        "\n",
        "**Недостатки:**\n",
        "\n",
        "- меньшая точность сегментации по сравнению с полноразмерными segmentation-моделями;  \n",
        "- зависимость качества от точности разметки.\n",
        "\n",
        "### Модель 2: U-Net / DeepLabv3+\n",
        "\n",
        "**Преимущества:**\n",
        "\n",
        "- высокая точность пиксельной сегментации;  \n",
        "- хорошая интерпретируемость результатов.\n",
        "\n",
        "**Недостатки:**\n",
        "\n",
        "- высокая вычислительная сложность;  \n",
        "- низкая скорость инференса;  \n",
        "- высокая стоимость разметки данных.\n",
        "\n",
        "### Модель 3: EfficientDet\n",
        "\n",
        "**Преимущества:**\n",
        "\n",
        "- высокая точность детекции;  \n",
        "- поддержка объектов разного масштаба.\n",
        "\n",
        "**Недостатки:**\n",
        "\n",
        "- более сложная архитектура;  \n",
        "- более низкая скорость инференса по сравнению с YOLO.\n",
        "\n",
        "## Выбор модели для системы\n",
        "\n",
        "В рамках проекта выбрана модель **YOLOv11m**.\n",
        "\n",
        "### Обоснование выбора\n",
        "\n",
        "- соответствие требованиям по latency (**< 490 мс**);  \n",
        "- возможность обработки пиковых нагрузок (**2 334 RPS**) при горизонтальном масштабировании;  \n",
        "- баланс между скоростью и качеством;  \n",
        "- удобство деплоя в Kubernetes и интеграции с GPU-кластером;  \n",
        "- поддержка дообучения и адаптации под новые типы заболеваний.\n",
        "---\n",
        "# Часть 2: Проектирование архитектуры\n",
        "---\n",
        "# 1. Высокоуровневая архитектура системы\n",
        "\n",
        "Высокоуровневая архитектура системы (High-Level Design, HLD) описывает промышленную ML-платформу для мониторинга состояния сельскохозяйственных культур на основе мультиспектральных данных, получаемых с дронов. Система охватывает полный жизненный цикл данных и моделей: от сбора изображений и подготовки датасетов до **real-time инференса**, мониторинга качества и автоматического переобучения моделей.\n",
        "\n",
        "Архитектура спроектирована с учётом следующих целевых требований:\n",
        "\n",
        "- **Latency P95:** < 490 мс для онлайн-инференса  \n",
        "- **Пиковая нагрузка:** до 2 334 RPS  \n",
        "- **Доступность:** не ниже 99.95%  \n",
        "- **Масштабируемость:** горизонтальная, отсутствие единой точки отказа  \n",
        "\n",
        "Система логически разделена на три взаимосвязанных блока:\n",
        "\n",
        "1. **Offline Training** — обучение и обновление модели  \n",
        "2. **Real-time Inference** — онлайн-анализ данных  \n",
        "3. **Monitoring & Feedback Loop** — мониторинг и контроль деградации  \n",
        "\n",
        "## 1.1 Offline Training (Обучение модели)\n",
        "\n",
        "Блок **Offline Training** отвечает за подготовку данных, обучение моделей и их безопасную передачу в production.\n",
        "\n",
        "**Основные компоненты:**\n",
        "\n",
        "- **Drones with Multispectral Cameras (NIR / Red Edge / Red, RGB опционально)**  \n",
        "  Выполняют съёмку сельскохозяйственных угодий. Мультиспектральные каналы позволяют выявлять стресс растений на ранних стадиях, когда изменения в RGB-диапазоне ещё не выражены.\n",
        "\n",
        "- **API Gateway (NGINX / L7 + OAuth)**  \n",
        "  Приём данных, первичная валидация запросов, аутентификация и балансировка нагрузки между зонами доступности.\n",
        "\n",
        "- **Kafka Image Stream**  \n",
        "  Буферизация потоков изображений и метаданных при пиковой нагрузке (**до 2 334 RPS**, ~1.16 ГБ/с), предотвращает потерю данных и сглаживает пиковые нагрузки после массовых облётов.\n",
        "\n",
        "- **Object Storage (S3 / GeoTIFF)**  \n",
        "  Хранение сырых мультиспектральных изображений и производных спектральных карт. Данные делятся на горячее и холодное хранилище в зависимости от актуальности.\n",
        "\n",
        "- **Spectral Feature Extraction**  \n",
        "  Вычисление агроспецифических признаков (NDVI, NDRE, GNDVI и др.), формирующих входное представление для модели и повышающих устойчивость к визуальному шуму.\n",
        "\n",
        "- **Automated Labeling & Pseudo-Labels**  \n",
        "  Генерация псевдо-меток на основе предыдущих версий моделей и эвристических правил. Финальная валидация выполняется агрономами для формирования ground truth.\n",
        "\n",
        "- **Apache Airflow**  \n",
        "  Оркестрация пайплайнов подготовки данных и обучения, включая обработку дрифта и плановое переобучение.\n",
        "\n",
        "- **Training Pipeline (GPU Compute Cluster — NVIDIA A100)**  \n",
        "  Обучение модели сегментации (YOLOv11m) на GPU-кластере A100, что обеспечивает высокую пропускную способность и поддержку сложных аугментаций.\n",
        "\n",
        "- **MLflow Model Registry**  \n",
        "  Хранение версий моделей, параметров обучения, метрик качества и референсных распределений для последующего мониторинга дрифта.\n",
        "\n",
        "- **Deploy to Inference**  \n",
        "  Только проверенные модели, прошедшие валидацию, передаются в онлайн-инференс.\n",
        "\n",
        "## 1.2 Real-time Inference (Онлайн-анализ)\n",
        "\n",
        "Блок **Real-time Inference** обеспечивает оперативную обработку данных и формирование результатов для агрономов в near-real-time режиме.\n",
        "\n",
        "**Основные компоненты:**\n",
        "\n",
        "- **Incoming Drone Images**  \n",
        "  Поток изображений поступает после облёта или в режиме, близком к реальному времени.\n",
        "\n",
        "- **Kubernetes Cluster + GPU Operator**  \n",
        "  Инференс развёрнут в Kubernetes-кластере с GPU Operator. Используется **13 GPU NVIDIA T4** с автоскейлингом **4 → 15 инстансов**, что обеспечивает требуемую пропускную способность и **latency < 490 мс**.\n",
        "\n",
        "- **Inference Service (YOLOv11m + Multispectral Features)**  \n",
        "  Сегментация зон поражения и оценка степени стресса растений на основе мультиспектральных данных и спектральных индексов.\n",
        "\n",
        "- **Output Storage**  \n",
        "  - **PostgreSQL / Greenplum** — долговременное хранение результатов анализа и истории заболеваний по полям  \n",
        "  - **Redis** — кэш последних и часто запрашиваемых результатов для снижения нагрузки и ускорения отклика\n",
        "\n",
        "## 1.3 Monitoring & Feedback Loop\n",
        "\n",
        "Блок обеспечивает контроль качества работы системы, обнаружение деградации модели и замыкание цикла обучения.\n",
        "\n",
        "**Основные компоненты:**\n",
        "\n",
        "- **Kafka Feedback Stream**  \n",
        "  Асинхронная очередь для фидбека от агрономов и событий эксплуатации, используется для запуска повторного обучения.\n",
        "\n",
        "- **Monitoring (Prometheus + Grafana)**  \n",
        "  Сбор и визуализация:  \n",
        "  - инфраструктурных метрик (CPU/GPU, latency, throughput)  \n",
        "  - метрик модели (mAP, Precision, Recall)  \n",
        "  - метрик дрифта данных и предсказаний (PSI, KS)\n",
        "\n",
        "- **Feedback Loop**  \n",
        "  При обнаружении деградации модели или превышении порогов дрифта автоматически инициируется дообучение в Offline Training контуре.\n",
        "\n",
        "- **Agronomic Dashboard**  \n",
        "  Пользовательский интерфейс для агрономов, отображающий состояние полей, динамику заболеваний и рекомендации по обработке.\n",
        "\n",
        "**Схема Высокоуровневой архитектуры:**\n",
        "\n",
        "![Высокоуровневая архитектура системы](higharch.png)\n",
        "\n",
        "# 2. Архитектура Data Pipeline\n",
        "\n",
        "Data Pipeline описывает процесс сбора, валидации, разметки и подготовки мультиспектральных данных, используемых для обучения и инференса модели мониторинга состояния сельскохозяйственных культур.  \n",
        "Пайплайн сочетает **оффлайн batch-обработку** (Python / batch-скрипты для нормализации, коррекции и расчёта спектральных индексов) и **онлайн-обновление feature store** (Redis для хранения актуальных агро-признаков и метаданных), что позволяет одновременно обеспечивать воспроизводимость обучения и низкую задержку при инференсе.\n",
        "\n",
        "## 2.1 Сбор данных (Data Ingestion)\n",
        "\n",
        "На первом этапе осуществляется приём исходных данных с дронов и их первичная буферизация.\n",
        "\n",
        "- **Drones with Multispectral Cameras**  \n",
        "  Беспилотные летательные аппараты выполняют съёмку сельскохозяйственных полей в мультиспектральных диапазонах (NIR, Red Edge, Red); RGB-канал используется опционально для визуальной проверки и экспертного анализа.\n",
        "\n",
        "- **API Gateway**  \n",
        "  Обеспечивает приём изображений и метаданных с дронов, аутентификацию, контроль формата запросов и балансировку нагрузки между зонами доступности.\n",
        "\n",
        "- **Kafka Image Stream**  \n",
        "  Используется для асинхронной буферизации потока изображений и метаданных, что позволяет сглаживать пиковые нагрузки после массовых облётов и предотвращать потерю данных.\n",
        "\n",
        "## 2.2 Архивирование и хранение сырых данных\n",
        "\n",
        "После приёма данные сохраняются для последующей оффлайн-обработки и переобучения моделей.\n",
        "\n",
        "- **Object Storage (S3-совместимое хранилище)**  \n",
        "  Сырые мультиспектральные изображения и связанные метаданные архивируются в объектном хранилище.  \n",
        "  Данные хранятся с разделением на горячее и холодное хранилище в зависимости от давности и частоты использования.\n",
        "\n",
        "## 2.3 Оффлайн обработка и подготовка датасетов (Offline Batch Processing)\n",
        "\n",
        "Оффлайн-пайплайн отвечает за формирование обучающих и валидационных наборов данных.\n",
        "\n",
        "- **Data Validation**  \n",
        "  Проверка корректности формата изображений, целостности спектральных каналов и метаданных (GPS-координаты, параметры сенсора, время облёта).\n",
        "\n",
        "- **Data Preprocessing / Enrichment**\n",
        "  - нормализация и приведение изображений к целевому формату;\n",
        "  - коррекция освещения и сенсорных искажений;\n",
        "  - геометрическая коррекция и выравнивание снимков;\n",
        "  - обогащение данных контекстными признаками (погодные условия, тип почвы, агрономические характеристики).\n",
        "\n",
        "- **Spectral Feature Extraction**  \n",
        "  Вычисление агроспецифических спектральных индексов (NDVI, NDRE, GNDVI и др.).\n",
        "\n",
        "- **Pseudo-labeling**  \n",
        "  Генерация псевдо-меток на основе предыдущих версий моделей для pre-training и data augmentation.\n",
        "\n",
        "- **Human Labeling UI (Roboflow)**  \n",
        "  Агрономы и эксперты проверяют и корректируют разметку ключевых участков, формируя ground truth.\n",
        "\n",
        "- **Dataset Management (DVC)**\n",
        "  - **Train Dataset** — обучающая выборка;\n",
        "  - **Eval Dataset** — validation и test выборки для оценки модели.\n",
        "\n",
        "## 2.4 Онлайн Feature Store и инференс  \n",
        "\n",
        "- **Redis Feature Store**  \n",
        "  Хранение последних агро-признаков и метаданных по каждому полю с задержкой доступа менее 10 мс.\n",
        "\n",
        "- **Inference API**  \n",
        "  Принимает новые мультиспектральные снимки после облёта.\n",
        "\n",
        "- **Context Merger**  \n",
        "  Асинхронно обновляет Feature Store и агрегирует контекст (последние N снимков по полю).\n",
        "\n",
        "- **YOLOv11m (fine-tuned)**  \n",
        "  Выполняет сегментацию зон поражения и оценку степени стресса растений.\n",
        "\n",
        "- **Output Storage**\n",
        "  - **Greenplum / SQL** — долговременное хранение результатов анализа и истории состояния полей;\n",
        "  - **Redis Cache** — быстрый доступ к последним результатам.\n",
        "\n",
        "## Выводы\n",
        "\n",
        "- Обработка данных в **near real-time** за счёт Kafka и Redis.\n",
        "- Автоматический мониторинг качества данных и **drift detection** с триггером на переобучение в MLflow.\n",
        "- Снижение объёма ручной разметки через **pseudo-labels** и human-in-the-loop.\n",
        "- Полная воспроизводимость экспериментов и версионирование данных и моделей.\n",
        "- Высокая масштабируемость и низкая задержка (**latency ≤ 385 мс**) при пиковой нагрузке до **2 334 RPS**.\n",
        "\n",
        "\n",
        "**Схема Архитектуры Data Pipeline:**\n",
        "\n",
        "![Архитектура Data Pipeline](high_level_architecture.svg)\n",
        "\n",
        "# 3. Архитектура Training Pipeline\n",
        "\n",
        "Training Pipeline описывает автоматизированный и воспроизводимый процесс обучения и дообучения модели детекции поражённых зон сельскохозяйственных культур на основе мультиспектральных данных.  \n",
        "Пайплайн реализован с использованием MLOps-инструментов (**Kubeflow Orchestrator, MLflow, DVC**) и GPU-кластера и поддерживает обучение, валидацию и безопасное развертывание моделей в промышленной среде.\n",
        "\n",
        "Pipeline может запускаться по расписанию, при накоплении новых размеченных данных или при обнаружении **data / concept drift** в production-потоке.\n",
        "\n",
        "## 3.1 Триггеры запуска обучения (Triggers)\n",
        "\n",
        "Обучение модели инициируется одним из следующих событий:\n",
        "\n",
        "- **Scheduled Trigger**  \n",
        "  Автоматический запуск по расписанию (ежедневно или еженедельно) для регулярного обновления модели.\n",
        "\n",
        "- **New Labeled Data Trigger**  \n",
        "  Запуск при накоплении заданного количества новых размеченных изображений, подготовленных в Data Pipeline и версионируемых с помощью DVC.\n",
        "\n",
        "- **Data / Concept Drift Trigger**  \n",
        "  Production-данные из Kafka, Redis и S3 анализируются на наличие дрифта.  \n",
        "  При превышении порогов (PSI > 0.2, KS > 0.1 или снижение Precision / Recall более чем на 10%) Kubeflow Orchestrator автоматически инициирует retraining.\n",
        "\n",
        "## 3.2 Подготовка данных к обучению\n",
        "\n",
        "- Финальный датасет загружается из **Data Pipeline (DVC)**.\n",
        "- Данные разделяются на **Train / Validation / Test** выборки с учётом временной структуры (time-based split).\n",
        "- Выполняется балансировка классов с учётом сезонности и географии.\n",
        "- Применяются аугментации:\n",
        "  - геометрические трансформации;\n",
        "  - изменение яркости и добавление шума;\n",
        "  - спектральные трансформации.\n",
        "- В датасет добавляются **pseudo-labels** для расширения обучающей выборки и pre-training.\n",
        "\n",
        "## 3.3 Обучение и fine-tuning модели\n",
        "\n",
        "- В качестве базовой архитектуры используется **YOLOv11m**, инициализированная предобученными весами (COCO).\n",
        "- Fine-tuning выполняется на мультиспектральных данных с повышенным приоритетом для последних и high-drift примеров.\n",
        "- Подбор гиперпараметров осуществляется с использованием **Optuna** (learning rate, batch size, политики аугментаций).\n",
        "- Обучение выполняется на распределённом **GPU-кластере NVIDIA A100** с использованием mixed precision для ускорения вычислений.\n",
        "- Все параметры и промежуточные результаты логируются в **MLflow**.\n",
        "\n",
        "## 3.4 Валидация и контроль качества модели\n",
        "\n",
        "- Оценка модели проводится на **Validation и Test выборках**, включая временные окна с зафиксированным дрифтом.\n",
        "- Используемые метрики:\n",
        "  - **mAP@0.5**\n",
        "  - **Precision**\n",
        "  - **Recall**\n",
        "  - **F1-score**\n",
        "- Дополнительно выполняется анализ bias:\n",
        "  - subgroup F1 по полям;\n",
        "  - по культурам;\n",
        "  - по регионам.\n",
        "- Все метрики сохраняются в **MLflow Metrics** для сравнения версий моделей.\n",
        "- При недостижении целевых значений pipeline автоматически возвращается к этапу обучения.\n",
        "- При успешной валидации запускается **Shadow Testing** (A/B-тестирование на ограниченной группе полей).\n",
        "\n",
        "## 3.5 Регистрация и развертывание модели\n",
        "\n",
        "- Успешная модель упаковывается в **Docker-образ**.\n",
        "- Модель регистрируется в **MLflow Model Registry** с версионированием и сохранением reference distributions для мониторинга дрифта.\n",
        "- Развертывание выполняется в **Kubernetes** с использованием canary или rolling update без простоя сервиса.\n",
        "\n",
        "## 3.6 Выводы\n",
        "\n",
        "- Полностью автоматизированный и воспроизводимый процесс обучения.\n",
        "- Быстрая адаптация модели к изменению данных за счёт drift-based retraining.\n",
        "- Безопасный деплой только валидированных моделей.\n",
        "- Поддержка масштабируемости, отказоустойчивости и мониторинга в реальном времени.\n",
        "\n",
        "**Схема Архитектуры Training Pipeline:**\n",
        "\n",
        "![Архитектура Training Pipeline](high_level_architecture.svg)\n",
        "\n",
        "## 4. Архитектура Inference Pipeline (Serving)\n",
        "\n",
        "Inference Pipeline описывает систему обработки мультиспектральных данных в реальном времени и предназначен для выявления стрессовых и поражённых зон сельскохозяйственных культур с минимальной задержкой ответа (**< 385 мс**) и поддержкой пиковой нагрузки до **~2 334 RPS**.  \n",
        "Архитектура ориентирована на агросценарии и учитывает работу со спектральными признаками (NDVI, NDRE, GNDVI), историей поля и масштабируемостью GPU-инференса.\n",
        "\n",
        "### 4.1 Ввод и приём данных\n",
        "\n",
        "- **Drones with Multispectral Cameras (NIR, Red Edge, Red; optional RGB)**  \n",
        "  Формируют мультиспектральные снимки полей после облёта.\n",
        "\n",
        "- **API Gateway / Load Balancer (NGINX)**  \n",
        "  Выполняет аутентификацию, rate limiting и распределение запросов между сервисами.\n",
        "\n",
        "- **Kafka Image Stream**  \n",
        "  Буферизует поток изображений, обеспечивая асинхронную обработку и устойчивость к пиковым нагрузкам.\n",
        "\n",
        "*Комментарий:* входной контур отделён от инференса, что предотвращает потерю данных и деградацию latency при массовых облётах.\n",
        "\n",
        "### 4.2 Контекст и Feature Store\n",
        "\n",
        "- **Redis Feature Store**  \n",
        "  Хранит последние агро-признаки и контекст по каждому полю (история замеров, сезонность, метаданные).\n",
        "\n",
        "- Обновление признаков осуществляется асинхронно через Kafka.\n",
        "\n",
        "*Комментарий:* использование Redis позволяет учитывать исторический контекст и снижает время подготовки данных для инференса до <10 мс.\n",
        "\n",
        "### 4.3 Сервис инференса\n",
        "\n",
        "- **Inference Pods (YOLOv11m + Spectral Features)**  \n",
        "  Выполняют сегментацию поражённых зон и оценку стресса растений на основе мультиспектральных признаков.\n",
        "\n",
        "- **GPU-ускоренный инференс (NVIDIA T4)**  \n",
        "  Используется для обработки изображений в реальном времени с поддержкой mixed precision.\n",
        "\n",
        "- **Kubernetes HPA (Horizontal Pod Autoscaler)**  \n",
        "  Масштабирует количество подов в зависимости от загрузки GPU, CPU и показателей latency.\n",
        "\n",
        "*Комментарий:* независимое масштабирование инференса позволяет выдерживать пиковые нагрузки без увеличения времени ответа.\n",
        "\n",
        "### 4.4 Хранение и визуализация результатов\n",
        "\n",
        "- **Greenplum / PostgreSQL**  \n",
        "  Хранение сегментаций, оценок стресса, временных рядов и метаданных по полям.\n",
        "\n",
        "- **Redis Cache**  \n",
        "  Кэширование последних результатов для быстрого доступа.\n",
        "\n",
        "- **Agronomist Dashboard**  \n",
        "  Визуализация зон стресса и рекомендаций для агрономов, поддержка принятия решений.\n",
        "\n",
        "*Комментарий:* аналитический слой изолирован от инференса, что исключает влияние пользовательских запросов на производительность модели.\n",
        "\n",
        "### 4.5 Мониторинг, качество и дрифт\n",
        "\n",
        "- **Prometheus**  \n",
        "  Сбор метрик инференса (latency, throughput, GPU utilization).\n",
        "\n",
        "- **Grafana**  \n",
        "  Дашборды и алерты для оперативного мониторинга системы.\n",
        "\n",
        "- **Data / Concept Drift Detection (PSI, KS, MMD)**  \n",
        "  Анализ изменений распределений признаков и выходов модели.\n",
        "\n",
        "- При превышении порогов дрифта автоматически формируется триггер на retraining в Training Pipeline.\n",
        "\n",
        "*Комментарий:* мониторинг и дрифт-детекция обеспечивают стабильное качество модели в условиях сезонных и региональных изменений.\n",
        "\n",
        "### 4.6 Выводы\n",
        "\n",
        "- Реальное время обработки мультиспектральных изображений.\n",
        "- Низкая задержка ответа (**< 385 мс**).\n",
        "- GPU-ускоренный инференс с автоматическим масштабированием.\n",
        "- Устойчивость к пиковым нагрузкам и отказам.\n",
        "- Прямая интеграция с Training Pipeline через дрифт-триггеры.\n",
        "\n",
        "\n",
        "**Схема Архитектуры Inference Pipeline:**\n",
        "\n",
        "![Архитектура Inference Pipeline](high_level_architecture.svg)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "# Часть 3: Расчёты и нефункциональные требования\n",
        "\n",
        "---\n",
        "\n",
        "В данном разделе представлены расчёты производительности, требований к хранилищу и масштабируемости промышленной ML-системы для мониторинга состояния сельскохозяйственных культур с использованием мультиспектральных данных с дронов. Расчёты учитывают архитектуру системы, SLA и выбранное оборудование (GPU NVIDIA A100 для обучения и T4 для инференса).\n",
        "\n",
        "## Нефункциональные требования\n",
        "\n",
        "Система должна удовлетворять следующим требованиям:\n",
        "\n",
        "- **Задержка (Latency, P95):** ≤ 490 мс для онлайн-инференса  \n",
        "- **Нагрузка:**  \n",
        "  - Активные пользователи: 4 673 977 DAU  \n",
        "  - Пиковая нагрузка: 2 334 RPS  \n",
        "- **Надёжность:**  \n",
        "  - Доступность сервиса: ≥ 99.95%  \n",
        "  - Отсутствие единой точки отказа (No SPOF)  \n",
        "- **Масштабируемость:**  \n",
        "  - Горизонтальное масштабирование инференса через Kubernetes HPA  \n",
        "  - Автоматическое масштабирование GPU-ресурсов  \n",
        "- **Производственная готовность:**  \n",
        "  - Stateless inference  \n",
        "  - Автоматическое обнаружение деградации модели  \n",
        "  - Возможность безопасного переобучения  \n",
        "\n",
        "## 1 Расчёт требований к хранилищу S3\n",
        "\n",
        "**Исходные данные:**\n",
        "\n",
        "- Основные мультиспектральные каналы: NIR, Red, Red Edge, float32, 2048×2048  \n",
        "- Опциональные RGB-каналы: 1024×1024, 8 бит/канал  \n",
        "\n",
        "**Размер одного изображения:**\n",
        "\n",
        "- Мультиспектральные: 3 × 2048 × 2048 × 4 байта ≈ **50,3 МБ**  \n",
        "- RGB (опционально): 3 × 1024 × 1024 × 1 байт ≈ **3 МБ**  \n",
        "- **Итого:** 50,3 + 3 ≈ **53,3 МБ**  \n",
        "\n",
        "**Поток данных в секунду:**\n",
        "\n",
        "- 5000 дронов × 1 снимок/мин → 5000 / 60 ≈ **85 RPS**  \n",
        "- Поток мультиспектральных каналов: 85 × 50,3 ≈ **4,28 ГБ/с**  \n",
        "- С RGB: 85 × 53,3 ≈ **4,53 ГБ/с**  \n",
        "\n",
        "**Объём данных за 8 часов работы дронов:**\n",
        "\n",
        "- Мультиспектральные: 4,28 × 3600 × 8 ≈ **123,2 ТБ**  \n",
        "- С RGB: 4,53 × 3600 × 8 ≈ **130,5 ТБ**  \n",
        "\n",
        "**Итоговое хранилище на 90 дней:**\n",
        "\n",
        "- Мультиспектральные: 123,2 × 90 ≈ **11,1 ПБ**  \n",
        "- С RGB: 130,5 × 90 ≈ **11,7 ПБ**  \n",
        "\n",
        "*Комментарий:* расчет включает только сырые изображения. Маски и артефакты для обучения увеличивают объём на 5–10%.\n",
        "\n",
        "\n",
        "## Расчёт требований к кэшу Redis\n",
        "\n",
        "**Параметры:**\n",
        "\n",
        "- Система обслуживает 4 673 977 DAU  \n",
        "- Среднее количество запросов на пользователя: 3  \n",
        "- Уникальные данные: 95%  \n",
        "\n",
        "**Размер сегментационной маски:**\n",
        "\n",
        "- 2048 × 2048 / 2^20 ≈ 4 МБ  \n",
        "\n",
        "**Суточная нагрузка на кэш:**\n",
        "\n",
        "- 4 673 977 × 3 × 0.95 × 4 МБ ≈ **53 317 ГБ (~52 ТБ)**  \n",
        "\n",
        "**Шардирование Redis:**\n",
        "\n",
        "- Один шард ≈ 256 ГБ  \n",
        "- Необходимо 52 000 / 256 ≈ **205 шардов**  \n",
        "\n",
        "*Комментарий:* Использование шардирования позволяет держать горячие данные в памяти без перегрузки одного узла.\n",
        "\n",
        "\n",
        "## 2 Расчёт требований к пропускной способности и инференсу\n",
        "\n",
        "**Выбранная модель:** YOLOv11m-Seg (мультиспектральные каналы + optional RGB)\n",
        "\n",
        "**Аппаратное обеспечение для инференса:** NVIDIA T4  \n",
        "\n",
        "**Производительность одного GPU:**\n",
        "\n",
        "- Среднее время инференса: ~4,7 мс  \n",
        "- Пропускная способность: ~212 RPS / GPU  \n",
        "\n",
        "**Требуемое количество GPU для 2 334 RPS:**\n",
        "\n",
        "- 2334 / 212 ≈ 11 GPU  \n",
        "- С учётом отказоустойчивости и нагрузки (N+2): **13 GPU T4**  \n",
        "\n",
        "**Пиковая нагрузка в сети:**\n",
        "\n",
        "- Входной трафик: 2 334 × 53,3 МБ ≈ **124 342 МБ/с (~121 ГБ/с)**  \n",
        "- Выходной трафик: 2 334 × (маска 4 МБ + рамки ~0,1 МБ) ≈ **9,6 ГБ/с**  \n",
        "\n",
        "*Комментарий:* входной трафик соответствует мультиспектральным каналам с опциональным RGB.\n",
        "\n",
        "\n",
        "## 3 Масштабируемость и надежность\n",
        "\n",
        "**Inference Pipeline:**\n",
        "\n",
        "- Kubernetes + HPA для подов с YOLOv11m-Seg  \n",
        "- Горизонтальное масштабирование: до **13 GPU T4**, автоскейлинг 4 → 15 при RPS/pending load  \n",
        "- Stateless pods для упрощения масштабирования  \n",
        "- Load Balancer + health checks  \n",
        "\n",
        "**Data Pipeline:**\n",
        "\n",
        "- Apache Kafka для пиковых нагрузок, горизонтальное масштабирование брокеров и партиций  \n",
        "- S3-совместимое хранилище для сырых и обработанных изображений  \n",
        "- Spark / PySpark для пакетной обработки и расчёта индексов  \n",
        "\n",
        "**Training Pipeline:**\n",
        "\n",
        "- GPU-кластер NVIDIA A100 для обучения и fine-tuning YOLOv11m  \n",
        "- Параллельные эксперименты с Optuna для поиска гиперпараметров  \n",
        "- Возможность добавления GPU-нод для увеличения пропускной способности  \n",
        "\n",
        "**Feature Store:**\n",
        "\n",
        "- Версионирование данных и моделей (MLflow + DVC)  \n",
        "- Горизонтальное масштабирование через шардинг и репликацию  \n",
        "\n",
        "**API и кэш:**\n",
        "\n",
        "- API Gateway с горизонтальной балансировкой нагрузки  \n",
        "- Redis-шардирование для горячих данных и сегментационных масок  \n",
        "\n",
        "**ЦОД и отказоустойчивость:**\n",
        "\n",
        "- Размещение в нескольких зонах доступности (Multi-AZ)  \n",
        "- Statless inference pods и Load Balancer  \n",
        "- Регулярные бэкапы S3, MLflow и PostgreSQL  \n",
        "- Канареечное развертывание новых моделей  \n",
        "- Мониторинг через Grafana / Prometheus и автоматический триггер переобучения при drift  \n",
        "\n",
        "## SLA и мониторинг\n",
        "\n",
        "- **Доступность:** 99,95%  \n",
        "- **Latency P95:** < 490 мс  \n",
        "- **Throughput:** 2 334 RPS с запасом 20%  \n",
        "- **Мониторинг:**\n",
        "  - CPU/GPU/RAM, Network  \n",
        "  - Data Drift (PSI, KS)  \n",
        "  - Prediction Drift  \n",
        "  - Метрики модели: mAP, Precision, Recall  \n",
        "\n",
        "---\n",
        "\n",
        "## Список использованных источников\n",
        "\n",
        "1. **YOLO Documentation**. Ultralytics. URL: [https://docs.ultralytics.com/modes/](https://docs.ultralytics.com/modes/)  \n",
        "2. **Huyen, C.** Designing Machine Learning Systems. O'Reilly Media, 2022.  \n",
        "3. **Kleppe, A.** ML System Design: Use Cases and Best Practices. O'Reilly Media, 2020.  \n",
        "4. **Apache Kafka Documentation**. Apache Software Foundation. URL: [https://kafka.apache.org/documentation/](https://kafka.apache.org/documentation/)  \n",
        "5. **MLflow Documentation**. Databricks. URL: [https://mlflow.org/docs/latest/index.html](https://mlflow.org/docs/latest/index.html)  \n",
        "6. **Kubernetes Documentation**. Kubernetes. URL: [https://kubernetes.io/docs/](https://kubernetes.io/docs/)  \n",
        "7. **Клеппман, М.** Designing Data-Intensive Applications: The Big Ideas Behind Reliable, Scalable, and Maintainable Systems. O’Reilly Media, 2017.  \n",
        "8. **Аминиан, А., Сюй, А.** System Design. Машинное обучение. Подготовка к сложному интервью. Санкт-Петербург: Питер, 2024.  \n",
        "9. **MLOps (Machine Learning Operations)**. Методология машинного обучения // TAdviser. URL: [Полный URL отсутствует]  \n",
        "10. **Amazon Compute Service Level Agreement**. Amazon Web Services. URL: [https://aws.amazon.com/compute/sla/](https://aws.amazon.com/compute/sla/)  "
      ],
      "metadata": {
        "id": "EawTvnv0YVVq"
      }
    }
  ]
}
